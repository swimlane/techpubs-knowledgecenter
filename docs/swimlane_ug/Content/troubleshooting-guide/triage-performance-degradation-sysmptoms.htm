<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd" style="mc-template-page: url('../Resources/MasterPages/OtherTopics.flmsp');">
    <head><title></title>
        <link href="../Resources/Stylesheets/MainStyles.css" rel="stylesheet" type="text/css" />
    </head>
    <body>
        <h1 id="triage-performance-degradation-symptoms">Triage Performance Degradation Symptoms</h1>
        <p>Swimlane performance degradation symptoms can arise for a variety of causes including:</p>
        <ul>
            <li>
                <p>Platform limitations</p>
            </li>
            <li>
                <p>Client code limitations</p>
            </li>
            <li>
                <p>Client job/data load upon the Platform</p>
            </li>
            <li>
                <p>Large record sets</p>
            </li>
            <li>
                <p>Suboptimal backup configuration</p>
            </li>
            <li>
                <p>Hardware limitations</p>
            </li>
            <li>
                <p>Any combination of these</p>
            </li>
        </ul>
        <p>Examples include:</p>
        <ul>
            <li>
                <p><a href="report-a-data-entry-lag-in-swimlane-records.htm">Text data entry lag</a>
                </p>
            </li>
            <li>
                <p>UI navigation and/or page-load speed slowdowns</p>
                <p>These sometimes manifest as HTTP 502 and 504 errors reported in Chrome Developer Tools.</p>
            </li>
            <li>
                <p>Poor performance when searching records or exporting records</p>
            </li>
            <li>
                <p>Timing out of Python script tasks that interact with the RESTful API</p>
                <p>These also sometimes manifest as HTTP 502 and 504 errors.</p>
            </li>
            <li>
                <p>Background job queue congestion</p>
            </li>
        </ul>
        <p>To triage performance degradation symptoms:</p>
        <ol>
            <li>
                <p>Take a screen capture video of the symptom while it is manifesting.</p>
                <p>Use video, screenshots, log file entries, etc, to help Swimlane support to get into context and see the symptom through your eyes.</p>
                <p>Your Swimlane support representative will join via Zoom to witness the symptom and can record the Zoom meeting screen sharing display.</p>
            </li>
            <li>
                <p>For UI slowness, <a href="https://toolbox.googleapps.com/apps/har_analyzer/">collect a HAR file</a> from Chrome Developer Tools.</p>
            </li>
            <li>
                <p>Use the watershed script to export a copy of all of your apps/workflows, integration tasks, and other related artifacts. You can request a copy of this script from your Swimlane Professional Services Engineer.</p>
            </li>
            <li>
                <p>Capture the MongoDB query profiler data. Work with your support representative on this.</p>
            </li>
            <li>
                <p>If requested by the your support representative, assist them to harvest MongoDB diagnostic and log data.</p>
                <p>These data can sometimes be large and require special arrangements for the file transfers.</p>
            </li>
            <li>
                <p>See the instructions below for background job queue congestion symptoms.</p>
            </li>
            <li>
                <p>Provide all of the artifacts above in the pertinent support portal ticket.</p>
            </li>
        </ol>
        <h2 id="tuning-scripts">Tuning Scripts</h2>
        <p>Whenever possible, you should attempt to refactor your automations targeting the RESTful API to:</p>
        <ul>
            <li>
                <p>Minimize the number of round trips to the RESTful API and remove superfluous calls to record.save() / record.patch().</p>
            </li>
            <li>
                <p>Minimize the load imposed on the RESTful API (and, by extension, the MongoDB database) in each round trip.</p>
                <p>Where possible, control the number of records against which searches are performed.</p>
                <ul>
                    <li>
                        <p>Make smart use of search APIs.</p>
                    </li>
                    <li>
                        <p>See <a href="https://swimlane-python-driver.readthedocs.io/en/stable/examples/resources.html#search-records">this resource</a> to:</p>
                        <ul>
                            <li>
                                <p>use the limit parameter appropriately with the Swimlane Driver’s app.records.search()</p>
                            </li>
                            <li>
                                <p>use app.reports.build() against large record sets</p>
                            </li>
                        </ul>
                    </li>
                    <li>
                        <p>Constrain the sorting order of results. This may work best in cases where only the first few results in a sorted set are really needed.</p>
                    </li>
                </ul>
                <p>The Driver does not support the RESTful API’s sorting interface formally. See below for a workaround. Note line 3:</p>
                <MadCap:codeSnippet>
                    <codeSnippetCopyButton />
                    <codeSnippetBody>report = soc_records_app.reports.build('source_ip_report', limit=0)
report.filter('First Created', GTE, dt.subtract(days=2))
report._raw['sorts']['Threat Score'] = 'ascending'
for record in report:
  # consume each resultant record
</codeSnippetBody>
                </MadCap:codeSnippet>
            </li>
        </ul>
        <h2 id="background-job-queue-congestion">Background Job Queue Congestion</h2>
        <p>The queue is congested whenever its <a href="https://swimlane.com/knowledge-center/docs/administrator-guide/system-settings/background-jobs">dashboard</a> shows that new jobs are being enqueued faster than previously enqueued jobs can finish processing.</p>
        <p>This symptom can be either the result of underlying performance problems or the cause of other performance degradation symptoms.</p>
        <p>When this symptom is severe (thousands or tens of thousands of enqueued jobs), it can prevent newly enqueued jobs from executing for hours or days.</p>
        <p>To understand this symptom and its remedies, it’s important to understand the queue itself. Each job is an instance of either:</p>
        <ul>
            <li>
                <p>A built-in integration task (one example is the nightly Directory Services sync).</p>
            </li>
            <li>
                <p>A customer-created integration task</p>
            </li>
        </ul>
        <p>As shown in the queue’s dashboard, each job passes through the following states:</p>
        <ol>
            <li>
                <p>Enqueued</p>
            </li>
            <li>
                <p>Processing</p>
            </li>
            <li>
                <p>Succeeded / Deleted (The Failed state is not used by Swimlane. Failed jobs are grouped in the Deleted state.)</p>
            </li>
        </ol>
        <p>There are other states such as Scheduled, Awaiting, or Aborted, but these are not used often.</p>
        <p>The quick fix to temporarily eliminate congestion is to work with your Swimlane support representative to purge the Background job queue to allow newer jobs to process. This works for a short time.</p>
        <p>!&gt; <strong>Important!</strong> Before purging the job queue consider the ramifications. The recommended purge method will delete all job execution data from the queue.</p>
        <p>Be aware that:</p>
        <ul>
            <li>
                <p>No Swimlane records will be altered by the purge (but they may suffer indirect harm as described below).</p>
            </li>
            <li>
                <p>Loss of knowledge of success/fail outcomes for completed jobs is often negligible because:</p>
                <ul>
                    <li>
                        <p>Information about Succeeded and Deleted jobs are purged automatically every night at midnight server time. Swimlane only retains this data for 24-48 hours.</p>
                    </li>
                    <li>
                        <p>This same information can often be reconstructed from the Swimlane log stream (the Swimlane.Logs collection in MongoDB).</p>
                    </li>
                </ul>
            </li>
        </ul>
        <p>However, the loss whose cost must be carefully considered is the elimination of the jobs in the Enqueued state. When thousands or tens of thousands of jobs are congested the following questions must be addressed:</p>
        <ul>
            <li>
                <p>Is it more harmful to leave these jobs enqueued knowing that recent Swimlane alarm records will go under-enriched for hours or days?</p>
            </li>
            <li>
                <p>Or, is it more harmful to eliminate all enqueued jobs so that subsequent jobs can start and finish more promptly?</p>
                <ul>
                    <li>
                        <p>To answer this question, consider the consequences of either:</p>
                        <ul>
                            <li>
                                <p>Leaving the recently ingested records under-enriched or</p>
                            </li>
                            <li>
                                <p>Putting forth special effort to back-fill the under-enriched records</p>
                                <ul>
                                    <li>Consult with your Professional Services Engineer for assistance using the Bulk Edit feature and/or special purpose scripts to catalyze enrichment on all records neglected during queue congestion.</li>
                                </ul>
                            </li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ul>
        <h3 id="diagnosing-the-queue">Diagnosing the Queue</h3>
        <ol>
            <li>
                <p>After stopping the Tasks service(s) and purging the queue, disable all Integration tasks.</p>
            </li>
            <li>
                <p>Decide on one small suit of tasks to enable.</p>
                <p>These tasks should all pertain to one use case (one security alarm type and its automation processing flow), but they may only be a subset of the tasks belonging to that use case.</p>
            </li>
            <li>
                <p>Enable only those chosen tasks.</p>
            </li>
            <li>
                <p>Monitor the job queue for 1-3 hours.</p>
                <p>Does Swimlane keep up with this reduced load of tasks?</p>
            </li>
            <li>
                <p>If Swimlane keeps up with the reduced load by never falling permanently behind, then add a few more tasks (completing the first use case’s portfolio or adding a small second use case), and continue monitoring.</p>
            </li>
            <li>
                <p>As soon as Swimlane falls behind permanently, then you know precisely how to increase load incrementally until the ability of the Swimlane deployment to keep up has been surpassed.</p>
            </li>
        </ol>
        <p>The information about which tasks were enabled, in what order, during what span of time, is the information you need to pass along (along with the other artifacts requested above) to provide a solution.</p>
    </body>
</html>